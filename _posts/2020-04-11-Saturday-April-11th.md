## Can we Make Science more Human

## When I first started learning how to code

- When I first started learning how to code, I was part of a Slack group with others who were learning how to code.
  One of the members of the group, who was working in industry, had commented, in response to the reaction from some others
  on the channel that he "forgot that most of us did not come from a hard sciences background, and that if we did, we would
  know that Science (or rather, the academic study of Science) is dehumanizing". 
- My opinion, from what I've seen (and having come from both a hard
  sciences background *and* a liberal arts background; I was one of those early hybrids!), is that people in Science deflect
  from answering difficult and uncomfortable questions. They deflect these questions by saying such statements, because 
  it is a method for not having to think or dig deeply into more difficult and challenging questions about the work they do
  and larger social implications; we'll just pass it off by saying our field discourages the human element. Gross.
- I thought about this a lot in the context of some (really late and) bad news about a friend, and some other news 
  about another close relative who passed away a few years ago that I found out had relayed to a stranger that they 
  thought that their life had been a waste. In a timely discussion, this week's topic for an online book club was on Ethics
  in Science, particularly with respect to AI. It brought me back to my own internal conflict with a professor, 
  where I discussed that I was driven to do research that I thought was important, and that was able to impact the world
  in a way that would help others. We disagreed on the extent to which fields we cared about or had a passion for 
  did this. 
- The bigger question of this post is whether, as someone who works in something seen as sort of a "dehumanizing field",
  Computer Science, or Science, can be seen as meaningful to the human condition. Can Science give a human life meaning?
- I have had these discussions with some of my engineering friends, particularly those who moved to tech meccas like Silicon
  Valley, who after spending around five to ten years, don't seem to feel like what they do matters, or has meaning anymore.
  They feel burnt out, and aren't energized by their work, or feel that what they do isn't meaningful. The implication is
  that there isn't a correlation between what the work promises to do in terms of impact for others, and what it actually
  delivers. Furthermore, this can be analyzed both on an individual and collectivist level; it is one thing for an individual
  to feel unfulfilled by one's work, but quite another for large groups of people to feel like their work lacks meaning or
  impact in the human world. 
  
## To this end

- This led to my enrolling in a Data Privacy Law course this upcoming semester, which will be on Privacy Policy and Law.
  Like some of the other machine learning projects I'm involved in, I'm taking part because I see them as holistically
  being beneficial to my training as a research scientist, and as a human being. I want to know how what I invest in
  both in terms of research and technology is harmful or could be harmful, and the measures of uncertainty of those 
  assessments, particularly when dealing with data. 
  
## Embedded Ethics
- Years ago I attended a Data Science event in San Jose in which a speaker (I apologize for forgetting the name) spoke
  about the different tribes of Data Scientists. He spoke about:
  - the Symbolists
  - the Bayesians
  - the Connectionists
  - the Evolutionaries
  - the Analogizers
- Each group had a preferred tool based on their theory of intelligence and analysis, and I think about how those tools
  or schools of thought influence the work and opportunity costs of the work they do. There is a currenty a group of 
  persons in deep learning who are working on [causal influence in Machine Learning](https://arxiv.org/pdf/1902.02302v4.pdf), 
  which is also interesting.
  
## Earlier this year
- Earlier this year I was invited to speak on a panel for a workshop at this conference 
that focuses on [Fairness and Transparency](https://facctconference.org/). I wasn't able to get my visa and passport together
  in time to make that a reality, but I've been realizing that it's such an important part of the way I am involved and
  engaged during my time as a PhD student. It has been one of the things that has given my work and life as a PhD
  student meaning. 
- We talk about mental health, abuse and bullying in tech, but I think it would be really great if moving forward,
  companies and teams spoke more about things that gave meaning in tech. I say this also not as a beckoning to the shallow, 
  corporate public relations self-posturing of tech, but rather, I am suggesting the deeper, uncomfortable conversations
  about what is and isn't working with technology, why people lose their sense of self in tech, and how people can find
  meaning in the work they do in tech. 
  
## I don't have too much else to say on this
- I'm lost in the papers of others, under the shadow of others and of a system that seems to tell me again and again
  that it was not meant for me. What does mean for an individual who wants to succeed in spite of that? Does that person
  have to give up something about themselves to make it through such a system? Can they have an impact and change the system
  in some small way just by being a part of that very system? And how much of themselves must they give up, 
  and is that damage reparable?
  
## I guess that these are questions I can't answer
- This post is a question, a discussion, and part of a stream of thoughts strung together.
- And that's it.
  
  
  
